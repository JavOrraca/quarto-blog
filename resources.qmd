---
title: "Python & R Resources"
title-block-banner: false
toc: true
toc-title: "Table of Contents"
toc-location: left
---

For anyone dipping their toes into the world of code-first data analysis, the best thing you could do for yourself is to learn SQL. This is the most widely used tool in the corporate world for interacting with system data stored in enterprise data warehouses. If you master SQL, you've mastered _most_ of the transformations that are possible for tabular, rectangular data. That said, I will _not_ cover SQL resources here as I rarely write raw SQL anymore - It's just not needed when Python and R can establish data warehouse connections _easily_ and it allows me to stay within the world of Python or R for end-to-end data analysis including data collection, manipulation, machine learning, GenAI, etc.

Python and R are open-source programming languages for data analysis, applied statistical programming, machine learning, working with REST APIs, developing ultra-fast web apps, and generalized software development. One of the things that I like most about both languages is the thousands of packages available making *almost everything* you want to do in Python or R _just_ a little easier from ETL, to method chaining, to creating interactive content. I certainly welcome any suggestions that you might have for the lists below, thanks!

## Python Books

* [The Quick Python Book (3e)](https://www.manning.com/books/the-quick-python-book-third-edition): This book by Naomi Ceder is a few years old now (2018) but it's the best end-to-end intro on Python that I've yet read taking you from basic classes / structures to function writing to working with modules
* [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/): Introduction to the core libraries essential for working with data in Python
* [Effective Pandas 2: Opinionated Patterns for Data Manipulation](https://store.metasnake.com/effective-pandas-book): After a wildly successful 1st edition, Matt Harrison is back with the revised 2nd edition with easy to follow tutorials for mastering the popular Pandas library
* [Tidy Finance with Python](https://www.tidy-finance.org/python/): This is one of my favorite newer books covering complex financial modeling, valuation, and pricing and represents "an opinionated approach to empirical research in financial economics [with an] open-source code base"

## Python Packages

* [NumPy](https://numpy.org/): Brings the computational power of C and Fortran to Python programmers for applying high-level mathematical functions to arrays and more
* [Pandas](https://pandas.pydata.org/): This is the most popular package for data manipulation and analysis with extended operations available for tabular and time series data
* [uv](https://docs.astral.sh/uv/guides/install-python/): A modern, high-performance Python package manager / installer written in Rust that serves as a drop-in replacement for traditional Python package management tools like `pip`
* [Narwhals](https://narwhals-dev.github.io/narwhals/): Extremely lightweight compatibility layer between dataframe libraries with support for pandas, Polars, PyArrow, DuckDB, Ibis, Modin, Vaex, and anything which implements the DataFrame Interchange Protocol
* [Matplotlib](https://matplotlib.org/): A comprehensive library for creating static, animated, and interactive visualizations in Python
* [Great Tables](https://posit-dev.github.io/great-tables/articles/intro.html): Absolutely delightful table-making in Python
* [scikit-learn](https://scikit-learn.org/stable/): Built on top of NumPy, SciPy, and matplotlib, "sklearn" makes the development of predictive analysis workflows a simple and reproducible process

## R Books: Classics

* [R for Data Science (2e)](https://r4ds.hadley.nz/): Phenomenal introduction to R, the RStudio IDE, and the `tidyverse` collection of packages
* [Advanced R (2e)](https://adv-r.hadley.nz/): Covers concepts, methods, and advanced object-oriented structures for R
* [Mastering Shiny](https://mastering-shiny.org/): Designed to teach the foundations of Shiny for web development and more advanced concepts such as the introduction of modules to the Shiny framework
* [R Packages (2e)](https://r-pkgs.org/): The definitive reference point for R package development "covering workflow and process, alongside the presentation of all the important moving parts that make up an R package"

## R Books: Applied Resources

* [Tidy Modeling with R](https://www.tmwr.org/): Over the last few months, I've learned a lot from this A to Z resource on predictive modeling workflows using the tidymodels framework
* [Supervised Machine Learning for Text Analysis in R](https://smltar.com/): This book is a masterclass in natural language processing taking you from the basics of NLP to real-life applications including inference and prediction
* [Forecasting Principles and Practice (3e)](https://otexts.com/fpp3/): Said best by the author, "The book is written for three audiences: (1) people finding themselves doing forecasting in business when they may not have had any formal training in the area; (2) undergraduate students studying business; (3) MBA students doing a forecasting elective"
* [Deep Learning with R (2e)](https://www.manning.com/books/deep-learning-with-r-second-edition): In-depth introduction to artificial intelligence and deep learning applications with R using the Keras library (Note: This book hasn't been updated since the release of [Keras3](https://keras.io/keras_3/), but the concepts found in the book are still deep learning foundations)
* [Tidy Finance with R](https://www.tidy-finance.org/r/): This is one of my favorite newer books covering complex financial modeling, valuation, and pricing and represents "an opinionated approach to empirical research in financial economics [with an] open-source code base in multiple programming languages"
* [Feature Engineering A-Z](https://feaz-book.com/): A reference guide to nearly all feature engineering methods you will encounter with examples in R and Python

## R Packages

* [tidyverse](https://www.tidyverse.org/): A collection of packages for data manipulation and functional programming (I use dplyr, stringr, and purrr on a daily basis)
* [tidymodels](https://www.tidymodels.org/): Hands-down my preferred collection of packages for building reproducible machine learning recipes, workflows, model tuning, model stacking, and cross-validation
* [DT](https://rstudio.github.io/DT/): This is an R implementation of the popular `DataTables` JavaScript library that lets you build polished, configurable tables for use in web reports, slides, and Shiny apps
* [bslib](https://rstudio.github.io/bslib/): A modern UI toolkit for Shiny and Quarto based on Bootstrap that can be easily customized with Bootswatch theming and Sass variables.
* [leaflet](https://rstudio.github.io/leaflet/): R implementation of the popular Leaflet JavaScript library for developing interactive maps
* [embed](https://embed.tidymodels.org/): One of my go-to machine learning packages for data pre-processing with extra steps that are intended to be used with the [recipes](https://recipes.tidymodels.org/) framework for embedding categorical and numeric predictors into one or more numeric columns
* [renv](https://rstudio.github.io/renv/articles/renv.html): This package helps you create reproducible environments for your R projects to more easily manage package dependencies on your operating system vs your project directory 

## Language Agnostic Frameworks

* [Arrow](https://arrow.apache.org/): Apache Arrow is a columnar memory format for flat and hierarchical data, organized for efficient analytic operations, supporting zero-copy reads for lightning-fast data access without serialization overhead
* [DuckDB](https://duckdb.org/): DuckDB is an in-process SQL OLAP database management system capable of larger than memory tabular data processing and with a growing list of community extensions
* [Polars](https://www.pola.rs/): Polars is a lightning fast DataFrame library/in-memory query engine written in Rust and built upon the Arrow specification - It's a great tool for efficient data wrangling, data pipelines, snappy APIs and much more
* [Quarto](https://quarto.org/): An open-source scientific and technical publishing system that can be used with Python, R, Julia, and Observable to develop and deploy reproducible content such as articles, presentations, dashboards, websites, blogs, and e-books 
* [Shiny](https://shiny.posit.co/): Easily create highly interactive web apps with Python or R without the need for formal web app development skills
* [Spark](https://spark.apache.org/): Apache Spark is a multi-language engine for executing data engineering, data science, and machine learning on single-node machines or clusters
